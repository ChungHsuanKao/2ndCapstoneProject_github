{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import glob\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import math\n",
    "from collections import Counter\n",
    "import re\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime\n",
    "from pprint import pprint\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image as image_utils\n",
    "from keras.applications.imagenet_utils import decode_predictions\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.applications import VGG16\n",
    "\n",
    "import keras as keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dropout, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "celeb_align = glob.glob('MsCelebV1-Faces-Aligned.Samples/MsCelebV1-Faces-Aligned.Samples/**/*.jpg')\n",
    "background = glob.glob('cars_brad_bg/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image augumentation generator\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "img = load_img('MsCelebV1-Faces-Aligned.Samples/MsCelebV1-Faces-Aligned.Samples/m.0qfnmpt/0-FaceId-0.jpg')\n",
    "x = img_to_array(img)\n",
    "x = x.reshape((1,) + x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 224, 192, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for batch in datagen.flow(x, batch_size=1, save_to_dir='preview', save_prefix='sample', save_format='jpeg'):\n",
    "    i += 1\n",
    "    if i > 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare resized images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "celeb_align_re = []\n",
    "for i in range(0, len(celeb_align)):\n",
    "    temp_img = cv2.imread(celeb_align[i])\n",
    "    temp_img_resize = cv2.resize(temp_img, (150, 150))\n",
    "    celeb_align_re.append(temp_img_resize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "background_re = []\n",
    "for i in range(0, len(background)):\n",
    "    temp_img = cv2.imread(background[i])\n",
    "    temp_img_resize = cv2.resize(temp_img, (150, 150))\n",
    "    background_re.append(temp_img_resize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = np.concatenate((celeb_align_re, background_re), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_full_yes = list('1') * len(celeb_align_re)\n",
    "label_full_yes = [int(i) for i in label_full_yes]\n",
    "label_full_yes = np.asarray(label_full_yes)\n",
    "\n",
    "label_full_no = list('0') * len(background_re)\n",
    "label_full_no = [int(i) for i in label_full_no]\n",
    "label_full_no = np.asarray(label_full_no)\n",
    "\n",
    "label_full = np.concatenate((label_full_no, label_full_yes), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(feature, label_full, test_size = 0.33, stratify=label_full, random_state=1992)\n",
    "\n",
    "# Normalize data set to 0-to-1 range\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(150, 150, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1839 samples, validate on 906 samples\n",
      "Epoch 1/30\n",
      "1839/1839 [==============================] - 59s 32ms/step - loss: 0.2631 - acc: 0.9059 - val_loss: 0.7098 - val_acc: 0.5552\n",
      "Epoch 2/30\n",
      "1839/1839 [==============================] - 58s 32ms/step - loss: 0.0722 - acc: 0.9782 - val_loss: 0.0385 - val_acc: 0.9923\n",
      "Epoch 3/30\n",
      "1839/1839 [==============================] - 58s 31ms/step - loss: 0.0338 - acc: 0.9902 - val_loss: 0.0608 - val_acc: 0.9901\n",
      "Epoch 4/30\n",
      "1839/1839 [==============================] - 58s 32ms/step - loss: 0.0286 - acc: 0.9918 - val_loss: 0.0927 - val_acc: 0.9890\n",
      "Epoch 5/30\n",
      "1839/1839 [==============================] - 58s 31ms/step - loss: 0.0351 - acc: 0.9929 - val_loss: 0.0547 - val_acc: 0.9912\n",
      "Epoch 6/30\n",
      "1839/1839 [==============================] - 66s 36ms/step - loss: 0.0269 - acc: 0.9940 - val_loss: 0.0632 - val_acc: 0.9912\n",
      "Epoch 7/30\n",
      "1839/1839 [==============================] - 64s 35ms/step - loss: 0.0252 - acc: 0.9929 - val_loss: 0.0686 - val_acc: 0.9912\n",
      "Epoch 8/30\n",
      "1839/1839 [==============================] - 64s 35ms/step - loss: 0.0191 - acc: 0.9978 - val_loss: 0.1121 - val_acc: 0.9879\n",
      "Epoch 9/30\n",
      "1839/1839 [==============================] - 63s 34ms/step - loss: 0.0255 - acc: 0.9946 - val_loss: 0.0981 - val_acc: 0.9923\n",
      "Epoch 10/30\n",
      "1839/1839 [==============================] - 63s 34ms/step - loss: 0.0151 - acc: 0.9962 - val_loss: 0.0738 - val_acc: 0.9912\n",
      "Epoch 11/30\n",
      "1839/1839 [==============================] - 60s 32ms/step - loss: 0.0272 - acc: 0.9962 - val_loss: 0.0746 - val_acc: 0.9923\n",
      "Epoch 12/30\n",
      "1839/1839 [==============================] - 58s 32ms/step - loss: 0.0260 - acc: 0.9967 - val_loss: 0.0981 - val_acc: 0.9923\n",
      "Epoch 13/30\n",
      "1839/1839 [==============================] - 56s 31ms/step - loss: 0.0316 - acc: 0.9951 - val_loss: 0.1106 - val_acc: 0.9890\n",
      "Epoch 14/30\n",
      "1839/1839 [==============================] - 59s 32ms/step - loss: 0.0144 - acc: 0.9989 - val_loss: 0.0918 - val_acc: 0.9912\n",
      "Epoch 15/30\n",
      "1839/1839 [==============================] - 57s 31ms/step - loss: 0.0180 - acc: 0.9989 - val_loss: 0.1050 - val_acc: 0.9923\n",
      "Epoch 16/30\n",
      "1839/1839 [==============================] - 58s 32ms/step - loss: 0.0167 - acc: 0.9989 - val_loss: 0.1163 - val_acc: 0.9901\n",
      "Epoch 17/30\n",
      "1839/1839 [==============================] - 60s 33ms/step - loss: 0.0181 - acc: 0.9973 - val_loss: 0.0971 - val_acc: 0.9901\n",
      "Epoch 18/30\n",
      "1839/1839 [==============================] - 57s 31ms/step - loss: 0.0206 - acc: 0.9978 - val_loss: 0.0906 - val_acc: 0.9912\n",
      "Epoch 19/30\n",
      "1839/1839 [==============================] - 59s 32ms/step - loss: 0.0157 - acc: 0.9984 - val_loss: 0.0891 - val_acc: 0.9912\n",
      "Epoch 20/30\n",
      "1839/1839 [==============================] - 59s 32ms/step - loss: 0.0239 - acc: 0.9962 - val_loss: 0.0798 - val_acc: 0.9923\n",
      "Epoch 21/30\n",
      "1839/1839 [==============================] - 57s 31ms/step - loss: 0.0157 - acc: 0.9978 - val_loss: 0.1129 - val_acc: 0.9923\n",
      "Epoch 22/30\n",
      "1839/1839 [==============================] - 57s 31ms/step - loss: 0.0172 - acc: 0.9978 - val_loss: 0.0913 - val_acc: 0.9923\n",
      "Epoch 23/30\n",
      "1839/1839 [==============================] - 57s 31ms/step - loss: 0.0125 - acc: 0.9984 - val_loss: 0.1069 - val_acc: 0.9934\n",
      "Epoch 24/30\n",
      "1839/1839 [==============================] - 57s 31ms/step - loss: 0.0129 - acc: 0.9984 - val_loss: 0.1456 - val_acc: 0.9823\n",
      "Epoch 25/30\n",
      "1839/1839 [==============================] - 58s 32ms/step - loss: 0.0256 - acc: 0.9978 - val_loss: 0.0893 - val_acc: 0.9923\n",
      "Epoch 26/30\n",
      "1839/1839 [==============================] - 59s 32ms/step - loss: 0.0439 - acc: 0.9962 - val_loss: 0.1168 - val_acc: 0.9790\n",
      "Epoch 27/30\n",
      "1839/1839 [==============================] - 57s 31ms/step - loss: 0.0168 - acc: 0.9962 - val_loss: 0.1043 - val_acc: 0.9901\n",
      "Epoch 28/30\n",
      "1839/1839 [==============================] - 58s 32ms/step - loss: 0.0111 - acc: 0.9989 - val_loss: 0.0883 - val_acc: 0.9923\n",
      "Epoch 29/30\n",
      "1839/1839 [==============================] - 61s 33ms/step - loss: 0.0088 - acc: 0.9995 - val_loss: 0.0857 - val_acc: 0.9934\n",
      "Epoch 30/30\n",
      "1839/1839 [==============================] - 61s 33ms/step - loss: 0.0088 - acc: 0.9995 - val_loss: 0.1143 - val_acc: 0.9923\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14c2f69e8>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=32,\n",
    "    epochs=30,\n",
    "    validation_data=(X_test, y_test),\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test model with cropped face dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "celeb_crop = glob.glob('MsCelebV1-Faces-Cropped.Samples/MsCelebV1-Faces-Cropped.Samples/**/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "celeb_crop_re = []\n",
    "for i in range(0, len(celeb_crop)):\n",
    "    temp_img = cv2.imread(celeb_crop[i])\n",
    "    temp_img_resize = cv2.resize(temp_img, (150, 150))\n",
    "    celeb_crop_re.append(temp_img_resize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = np.array(celeb_crop_re)\n",
    "target = target.astype('float32')\n",
    "target /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.predict(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       ...,\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observe = [[1.0]] * len(celeb_crop_re)\n",
    "observe = np.asarray(observe)\n",
    "observe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06181818181818182"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(np.rint(result), observe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resized samples and save to 'data' folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### facial images in different folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = glob.glob('MsCelebV1-Faces-Aligned.Samples/MsCelebV1-Faces-Aligned.Samples/**')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = 'data/'\n",
    "\n",
    "for file in all_files:\n",
    "    # all paths in one folder\n",
    "    all_images = glob.glob(file+'/*.jpg')\n",
    "    for image in all_images:\n",
    "        # read image in an array\n",
    "        temp_img = cv2.imread(image,1)\n",
    "        # resize the array\n",
    "        temp_img_resize = cv2.resize(temp_img, (150, 150))\n",
    "        # split path and filename.jpg\n",
    "        path, name = os.path.split(image)\n",
    "        # get the folder name\n",
    "        folder_name = os.path.basename(file)\n",
    "        # write resized-array as an image into respective dir instead of working dir\n",
    "        cv2.imwrite(os.path.join(out_dir, \"resized_\" + folder_name + name), temp_img_resize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### background images in one folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images = glob.glob('cars_brad_bg/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = 'data/'\n",
    "\n",
    "for image in all_images:\n",
    "    # read image in an array\n",
    "    temp_img = cv2.imread(image,1)\n",
    "    # resize the array\n",
    "    temp_img_resize = cv2.resize(temp_img, (150, 150))\n",
    "    # split path and filename w/ extension\n",
    "    path, name = os.path.split(image)\n",
    "    # write resized-array as an image into respective dir instead of working dir\n",
    "    cv2.imwrite(os.path.join(out_dir, \"resized_\" + name), temp_img_resize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model1_aug (from 150 x 150 images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1935 images belonging to 2 classes.\n",
      "Found 810 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# this is a generator that will read pictures found in\n",
    "# subfolers of 'data/train', and indefinitely generate\n",
    "# batches of augmented image data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'data/train',  # this is the target directory\n",
    "        target_size=(150, 150),  # all images will be resized to 150x150\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')  # since we use binary_crossentropy loss, we need binary labels\n",
    "\n",
    "# this is a similar generator, for validation data\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        'data/test',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "120/120 [==============================] - 68s 567ms/step - loss: 0.3009 - acc: 0.8865 - val_loss: 0.1165 - val_acc: 0.9575\n",
      "Epoch 2/20\n",
      "120/120 [==============================] - 65s 545ms/step - loss: 0.0757 - acc: 0.9786 - val_loss: 0.1203 - val_acc: 0.9710\n",
      "Epoch 3/20\n",
      "120/120 [==============================] - 65s 544ms/step - loss: 0.0706 - acc: 0.9817 - val_loss: 0.0681 - val_acc: 0.9761\n",
      "Epoch 4/20\n",
      "120/120 [==============================] - 66s 549ms/step - loss: 0.0435 - acc: 0.9901 - val_loss: 0.0712 - val_acc: 0.9899\n",
      "Epoch 5/20\n",
      "120/120 [==============================] - 65s 540ms/step - loss: 0.0296 - acc: 0.9927 - val_loss: 0.1924 - val_acc: 0.9723\n",
      "Epoch 6/20\n",
      "120/120 [==============================] - 66s 546ms/step - loss: 0.0518 - acc: 0.9901 - val_loss: 0.4858 - val_acc: 0.9584\n",
      "Epoch 7/20\n",
      "120/120 [==============================] - 65s 541ms/step - loss: 0.0520 - acc: 0.9932 - val_loss: 0.0833 - val_acc: 0.9836\n",
      "Epoch 8/20\n",
      "120/120 [==============================] - 65s 544ms/step - loss: 0.0171 - acc: 0.9953 - val_loss: 0.1399 - val_acc: 0.9824\n",
      "Epoch 9/20\n",
      "120/120 [==============================] - 65s 544ms/step - loss: 0.0592 - acc: 0.9917 - val_loss: 0.1331 - val_acc: 0.9849\n",
      "Epoch 10/20\n",
      "120/120 [==============================] - 65s 544ms/step - loss: 0.0941 - acc: 0.9875 - val_loss: 0.0571 - val_acc: 0.9887\n",
      "Epoch 11/20\n",
      "120/120 [==============================] - 66s 547ms/step - loss: 0.0240 - acc: 0.9932 - val_loss: 0.0781 - val_acc: 0.9861\n",
      "Epoch 12/20\n",
      "120/120 [==============================] - 492s 4s/step - loss: 0.0320 - acc: 0.9958 - val_loss: 0.1773 - val_acc: 0.9786\n",
      "Epoch 13/20\n",
      "120/120 [==============================] - 66s 551ms/step - loss: 0.0222 - acc: 0.9969 - val_loss: 0.1003 - val_acc: 0.9861\n",
      "Epoch 14/20\n",
      "120/120 [==============================] - 65s 545ms/step - loss: 0.0085 - acc: 0.9979 - val_loss: 0.1718 - val_acc: 0.9849\n",
      "Epoch 15/20\n",
      "120/120 [==============================] - 65s 544ms/step - loss: 0.0182 - acc: 0.9968 - val_loss: 0.1014 - val_acc: 0.9874\n",
      "Epoch 16/20\n",
      "120/120 [==============================] - 66s 551ms/step - loss: 0.0181 - acc: 0.9953 - val_loss: 0.1082 - val_acc: 0.9887\n",
      "Epoch 17/20\n",
      "120/120 [==============================] - 65s 542ms/step - loss: 0.0129 - acc: 0.9979 - val_loss: 0.1713 - val_acc: 0.9811\n",
      "Epoch 18/20\n",
      "120/120 [==============================] - 69s 575ms/step - loss: 0.0127 - acc: 0.9958 - val_loss: 0.0651 - val_acc: 0.9861\n",
      "Epoch 19/20\n",
      "120/120 [==============================] - 65s 545ms/step - loss: 0.0379 - acc: 0.9943 - val_loss: 0.1027 - val_acc: 0.9899\n",
      "Epoch 20/20\n",
      "120/120 [==============================] - 68s 569ms/step - loss: 0.0142 - acc: 0.9969 - val_loss: 0.0685 - val_acc: 0.9874\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x135b42898>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=1935 // batch_size,\n",
    "        epochs=20,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=810 // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model structure\n",
    "from pathlib import Path\n",
    "model_structure = model.to_json()\n",
    "\n",
    "f = Path('model1_aug_structure.json')\n",
    "f.write_text(model_structure)\n",
    "\n",
    "# save model weights\n",
    "model.save_weights('model1_aug_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model2_aug (from 64 x 64 images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1935 images belonging to 2 classes.\n",
      "Found 810 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# this is a generator that will read pictures found in\n",
    "# subfolers of 'data/train', and indefinitely generate\n",
    "# batches of augmented image data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'data/train',  # this is the target directory\n",
    "        target_size=(64, 64),  # all images will be resized to 150x150\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')  # since we use binary_crossentropy loss, we need binary labels\n",
    "\n",
    "# this is a similar generator, for validation data\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        'data/test',\n",
    "        target_size=(64, 64),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(64, 64, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "120/120 [==============================] - 14s 116ms/step - loss: 0.2254 - acc: 0.9031 - val_loss: 0.0355 - val_acc: 0.9838\n",
      "Epoch 2/50\n",
      "120/120 [==============================] - 13s 110ms/step - loss: 0.0650 - acc: 0.9755 - val_loss: 0.0313 - val_acc: 0.9912\n",
      "Epoch 3/50\n",
      "120/120 [==============================] - 13s 111ms/step - loss: 0.0465 - acc: 0.9839 - val_loss: 0.2981 - val_acc: 0.9257\n",
      "Epoch 4/50\n",
      "120/120 [==============================] - 13s 110ms/step - loss: 0.0359 - acc: 0.9891 - val_loss: 0.0435 - val_acc: 0.9861\n",
      "Epoch 5/50\n",
      "120/120 [==============================] - 14s 116ms/step - loss: 0.0268 - acc: 0.9922 - val_loss: 0.1544 - val_acc: 0.9786\n",
      "Epoch 6/50\n",
      "120/120 [==============================] - 14s 114ms/step - loss: 0.0779 - acc: 0.9875 - val_loss: 0.0288 - val_acc: 0.9849\n",
      "Epoch 7/50\n",
      "120/120 [==============================] - 14s 118ms/step - loss: 0.0321 - acc: 0.9937 - val_loss: 0.0221 - val_acc: 0.9924\n",
      "Epoch 8/50\n",
      "120/120 [==============================] - 13s 110ms/step - loss: 0.0269 - acc: 0.9937 - val_loss: 0.1667 - val_acc: 0.9647\n",
      "Epoch 9/50\n",
      "120/120 [==============================] - 13s 108ms/step - loss: 0.0125 - acc: 0.9964 - val_loss: 0.0345 - val_acc: 0.9912\n",
      "Epoch 10/50\n",
      "120/120 [==============================] - 13s 111ms/step - loss: 0.0262 - acc: 0.9937 - val_loss: 0.1402 - val_acc: 0.9773\n",
      "Epoch 11/50\n",
      "120/120 [==============================] - 13s 111ms/step - loss: 0.0085 - acc: 0.9974 - val_loss: 0.0333 - val_acc: 0.9861\n",
      "Epoch 12/50\n",
      "120/120 [==============================] - 13s 111ms/step - loss: 0.0344 - acc: 0.9964 - val_loss: 0.0175 - val_acc: 0.9962\n",
      "Epoch 13/50\n",
      "120/120 [==============================] - 13s 110ms/step - loss: 0.0251 - acc: 0.9953 - val_loss: 0.0329 - val_acc: 0.9899\n",
      "Epoch 14/50\n",
      "120/120 [==============================] - 13s 110ms/step - loss: 0.0186 - acc: 0.9943 - val_loss: 0.0634 - val_acc: 0.9874\n",
      "Epoch 15/50\n",
      "120/120 [==============================] - 13s 109ms/step - loss: 0.0221 - acc: 0.9953 - val_loss: 0.0897 - val_acc: 0.9849\n",
      "Epoch 16/50\n",
      "120/120 [==============================] - 13s 110ms/step - loss: 0.0193 - acc: 0.9953 - val_loss: 0.0136 - val_acc: 0.9975\n",
      "Epoch 17/50\n",
      "120/120 [==============================] - 13s 112ms/step - loss: 0.0135 - acc: 0.9964 - val_loss: 0.0119 - val_acc: 0.9950\n",
      "Epoch 18/50\n",
      "120/120 [==============================] - 13s 111ms/step - loss: 0.0042 - acc: 0.9995 - val_loss: 0.0181 - val_acc: 0.9950\n",
      "Epoch 19/50\n",
      "120/120 [==============================] - 13s 111ms/step - loss: 0.0180 - acc: 0.9948 - val_loss: 0.0567 - val_acc: 0.9836\n",
      "Epoch 20/50\n",
      "120/120 [==============================] - 13s 109ms/step - loss: 0.0354 - acc: 0.9948 - val_loss: 0.0485 - val_acc: 0.9887\n",
      "Epoch 21/50\n",
      "120/120 [==============================] - 13s 108ms/step - loss: 0.0230 - acc: 0.9964 - val_loss: 0.0121 - val_acc: 0.9937\n",
      "Epoch 22/50\n",
      "120/120 [==============================] - 12s 103ms/step - loss: 0.0089 - acc: 0.9979 - val_loss: 0.0084 - val_acc: 0.9975\n",
      "Epoch 23/50\n",
      "120/120 [==============================] - 104s 868ms/step - loss: 0.0115 - acc: 0.9979 - val_loss: 0.0089 - val_acc: 0.9962\n",
      "Epoch 24/50\n",
      "120/120 [==============================] - 16s 130ms/step - loss: 0.0084 - acc: 0.9990 - val_loss: 0.0366 - val_acc: 0.9950\n",
      "Epoch 25/50\n",
      "120/120 [==============================] - 14s 120ms/step - loss: 0.0182 - acc: 0.9974 - val_loss: 0.0606 - val_acc: 0.9899\n",
      "Epoch 26/50\n",
      "120/120 [==============================] - 14s 121ms/step - loss: 0.0100 - acc: 0.9990 - val_loss: 0.0192 - val_acc: 0.9950\n",
      "Epoch 27/50\n",
      "120/120 [==============================] - 14s 113ms/step - loss: 6.7515e-07 - acc: 1.0000 - val_loss: 0.0909 - val_acc: 0.9861\n",
      "Epoch 28/50\n",
      "120/120 [==============================] - 14s 117ms/step - loss: 0.0219 - acc: 0.9964 - val_loss: 0.0536 - val_acc: 0.9924\n",
      "Epoch 29/50\n",
      "120/120 [==============================] - 14s 116ms/step - loss: 0.0064 - acc: 0.9990 - val_loss: 0.0362 - val_acc: 0.9874\n",
      "Epoch 30/50\n",
      "120/120 [==============================] - 14s 115ms/step - loss: 0.0034 - acc: 0.9990 - val_loss: 0.0275 - val_acc: 0.9950\n",
      "Epoch 31/50\n",
      "120/120 [==============================] - 14s 115ms/step - loss: 9.3733e-06 - acc: 1.0000 - val_loss: 0.0085 - val_acc: 0.9975\n",
      "Epoch 32/50\n",
      "120/120 [==============================] - 14s 115ms/step - loss: 0.0122 - acc: 0.9979 - val_loss: 0.0241 - val_acc: 0.9950\n",
      "Epoch 33/50\n",
      "120/120 [==============================] - 14s 115ms/step - loss: 0.0202 - acc: 0.9974 - val_loss: 0.1350 - val_acc: 0.9887\n",
      "Epoch 34/50\n",
      "120/120 [==============================] - 14s 116ms/step - loss: 0.0058 - acc: 0.9974 - val_loss: 0.0736 - val_acc: 0.9874\n",
      "Epoch 35/50\n",
      "120/120 [==============================] - 14s 117ms/step - loss: 1.7898e-04 - acc: 1.0000 - val_loss: 0.0323 - val_acc: 0.9962\n",
      "Epoch 36/50\n",
      "120/120 [==============================] - 14s 115ms/step - loss: 0.0360 - acc: 0.9953 - val_loss: 0.1234 - val_acc: 0.9824\n",
      "Epoch 37/50\n",
      "120/120 [==============================] - 14s 119ms/step - loss: 0.0103 - acc: 0.9990 - val_loss: 0.0121 - val_acc: 0.9962\n",
      "Epoch 38/50\n",
      "120/120 [==============================] - 15s 128ms/step - loss: 0.0095 - acc: 0.9984 - val_loss: 0.0456 - val_acc: 0.9924\n",
      "Epoch 39/50\n",
      "120/120 [==============================] - 15s 127ms/step - loss: 0.0132 - acc: 0.9979 - val_loss: 0.0150 - val_acc: 0.9950\n",
      "Epoch 40/50\n",
      "120/120 [==============================] - 16s 129ms/step - loss: 0.0016 - acc: 0.9995 - val_loss: 0.1144 - val_acc: 0.9811\n",
      "Epoch 41/50\n",
      "120/120 [==============================] - 15s 124ms/step - loss: 0.0078 - acc: 0.9979 - val_loss: 0.2100 - val_acc: 0.9798\n",
      "Epoch 42/50\n",
      "120/120 [==============================] - 15s 122ms/step - loss: 0.0328 - acc: 0.9958 - val_loss: 0.0901 - val_acc: 0.9912\n",
      "Epoch 43/50\n",
      "120/120 [==============================] - 15s 123ms/step - loss: 0.0221 - acc: 0.9974 - val_loss: 0.0153 - val_acc: 0.9950\n",
      "Epoch 44/50\n",
      "120/120 [==============================] - 15s 122ms/step - loss: 7.5782e-04 - acc: 0.9995 - val_loss: 0.0812 - val_acc: 0.9912\n",
      "Epoch 45/50\n",
      "120/120 [==============================] - 14s 120ms/step - loss: 0.0062 - acc: 0.9990 - val_loss: 0.0464 - val_acc: 0.9937\n",
      "Epoch 46/50\n",
      "120/120 [==============================] - 15s 126ms/step - loss: 2.3088e-06 - acc: 1.0000 - val_loss: 0.1712 - val_acc: 0.9798\n",
      "Epoch 47/50\n",
      "120/120 [==============================] - 15s 124ms/step - loss: 0.0084 - acc: 0.9995 - val_loss: 0.0349 - val_acc: 0.9937\n",
      "Epoch 48/50\n",
      "120/120 [==============================] - 16s 132ms/step - loss: 0.0399 - acc: 0.9958 - val_loss: 0.0369 - val_acc: 0.9937\n",
      "Epoch 49/50\n",
      "120/120 [==============================] - 14s 118ms/step - loss: 0.0123 - acc: 0.9984 - val_loss: 0.1088 - val_acc: 0.9861\n",
      "Epoch 50/50\n",
      "120/120 [==============================] - 15s 128ms/step - loss: 0.0166 - acc: 0.9984 - val_loss: 0.0455 - val_acc: 0.9924\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13d421f98>"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=1935 // batch_size,\n",
    "        epochs=50,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=810 // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model structure\n",
    "from pathlib import Path\n",
    "model_structure = model.to_json()\n",
    "\n",
    "f = Path('model2_aug_structure.json')\n",
    "f.write_text(model_structure)\n",
    "\n",
    "# save model weights\n",
    "model.save_weights('model2_aug_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model3_aug (from 32 x 32 images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1935 images belonging to 2 classes.\n",
      "Found 810 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# this is a generator that will read pictures found in\n",
    "# subfolers of 'data/train', and indefinitely generate\n",
    "# batches of augmented image data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'data/train',  # this is the target directory\n",
    "        target_size=(32, 32),  # all images will be resized to 150x150\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')  # since we use binary_crossentropy loss, we need binary labels\n",
    "\n",
    "# this is a similar generator, for validation data\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        'data/test',\n",
    "        target_size=(32, 32),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(32, 32, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "120/120 [==============================] - 9s 77ms/step - loss: 0.3840 - acc: 0.8297 - val_loss: 0.1317 - val_acc: 0.9425\n",
      "Epoch 2/50\n",
      "120/120 [==============================] - 7s 59ms/step - loss: 0.0988 - acc: 0.9671 - val_loss: 0.1133 - val_acc: 0.9559\n",
      "Epoch 3/50\n",
      "120/120 [==============================] - 7s 57ms/step - loss: 0.0675 - acc: 0.9807 - val_loss: 0.1090 - val_acc: 0.9673\n",
      "Epoch 4/50\n",
      "120/120 [==============================] - 7s 60ms/step - loss: 0.0513 - acc: 0.9802 - val_loss: 0.1445 - val_acc: 0.9484\n",
      "Epoch 5/50\n",
      "120/120 [==============================] - 7s 61ms/step - loss: 0.0339 - acc: 0.9880 - val_loss: 0.0844 - val_acc: 0.9685\n",
      "Epoch 6/50\n",
      "120/120 [==============================] - 8s 64ms/step - loss: 0.0248 - acc: 0.9906 - val_loss: 0.0919 - val_acc: 0.9647\n",
      "Epoch 7/50\n",
      "120/120 [==============================] - 7s 59ms/step - loss: 0.0374 - acc: 0.9901 - val_loss: 0.0193 - val_acc: 0.9912\n",
      "Epoch 8/50\n",
      "120/120 [==============================] - 7s 59ms/step - loss: 0.0233 - acc: 0.9932 - val_loss: 0.0495 - val_acc: 0.9798\n",
      "Epoch 9/50\n",
      "120/120 [==============================] - 7s 59ms/step - loss: 0.0142 - acc: 0.9937 - val_loss: 0.1611 - val_acc: 0.9673\n",
      "Epoch 10/50\n",
      "120/120 [==============================] - 7s 60ms/step - loss: 0.0168 - acc: 0.9969 - val_loss: 0.2130 - val_acc: 0.9534\n",
      "Epoch 11/50\n",
      "120/120 [==============================] - 7s 59ms/step - loss: 0.0143 - acc: 0.9958 - val_loss: 0.0407 - val_acc: 0.9849\n",
      "Epoch 12/50\n",
      "120/120 [==============================] - 7s 59ms/step - loss: 0.0175 - acc: 0.9927 - val_loss: 0.1127 - val_acc: 0.9761\n",
      "Epoch 13/50\n",
      "120/120 [==============================] - 7s 58ms/step - loss: 0.0143 - acc: 0.9948 - val_loss: 0.1452 - val_acc: 0.9660\n",
      "Epoch 14/50\n",
      "120/120 [==============================] - 7s 59ms/step - loss: 0.0036 - acc: 0.9979 - val_loss: 0.7922 - val_acc: 0.8980\n",
      "Epoch 15/50\n",
      "120/120 [==============================] - 7s 59ms/step - loss: 0.0272 - acc: 0.9920 - val_loss: 0.0578 - val_acc: 0.9861\n",
      "Epoch 16/50\n",
      "120/120 [==============================] - 8s 63ms/step - loss: 0.0051 - acc: 0.9984 - val_loss: 0.0180 - val_acc: 0.9937\n",
      "Epoch 17/50\n",
      "120/120 [==============================] - 7s 60ms/step - loss: 0.0225 - acc: 0.9969 - val_loss: 0.0416 - val_acc: 0.9861\n",
      "Epoch 18/50\n",
      "120/120 [==============================] - 7s 61ms/step - loss: 0.0157 - acc: 0.9948 - val_loss: 0.0262 - val_acc: 0.9899\n",
      "Epoch 19/50\n",
      "120/120 [==============================] - 7s 59ms/step - loss: 0.0224 - acc: 0.9958 - val_loss: 0.0287 - val_acc: 0.9899\n",
      "Epoch 20/50\n",
      "120/120 [==============================] - 7s 62ms/step - loss: 0.0114 - acc: 0.9958 - val_loss: 0.0043 - val_acc: 1.0000\n",
      "Epoch 21/50\n",
      "120/120 [==============================] - 7s 62ms/step - loss: 0.0031 - acc: 0.9984 - val_loss: 0.0544 - val_acc: 0.9887\n",
      "Epoch 22/50\n",
      "120/120 [==============================] - 7s 62ms/step - loss: 0.0257 - acc: 0.9932 - val_loss: 0.0982 - val_acc: 0.9723\n",
      "Epoch 23/50\n",
      "120/120 [==============================] - 7s 61ms/step - loss: 0.0050 - acc: 0.9974 - val_loss: 0.0367 - val_acc: 0.9849\n",
      "Epoch 24/50\n",
      "120/120 [==============================] - 7s 61ms/step - loss: 0.0045 - acc: 0.9995 - val_loss: 0.0230 - val_acc: 0.9924\n",
      "Epoch 25/50\n",
      "120/120 [==============================] - 7s 61ms/step - loss: 0.0070 - acc: 0.9969 - val_loss: 0.2047 - val_acc: 0.9660\n",
      "Epoch 26/50\n",
      "120/120 [==============================] - 8s 63ms/step - loss: 0.0164 - acc: 0.9969 - val_loss: 0.0165 - val_acc: 0.9950\n",
      "Epoch 27/50\n",
      "120/120 [==============================] - 7s 62ms/step - loss: 0.0149 - acc: 0.9969 - val_loss: 0.0833 - val_acc: 0.9798\n",
      "Epoch 28/50\n",
      "120/120 [==============================] - 8s 63ms/step - loss: 0.0103 - acc: 0.9964 - val_loss: 0.0149 - val_acc: 0.9937\n",
      "Epoch 29/50\n",
      "120/120 [==============================] - 8s 64ms/step - loss: 0.0084 - acc: 0.9969 - val_loss: 0.1255 - val_acc: 0.9798\n",
      "Epoch 30/50\n",
      "120/120 [==============================] - 8s 63ms/step - loss: 0.0044 - acc: 0.9990 - val_loss: 0.1820 - val_acc: 0.9710\n",
      "Epoch 31/50\n",
      "120/120 [==============================] - 8s 65ms/step - loss: 0.0095 - acc: 0.9974 - val_loss: 0.3755 - val_acc: 0.9597\n",
      "Epoch 32/50\n",
      "120/120 [==============================] - 7s 61ms/step - loss: 0.0100 - acc: 0.9974 - val_loss: 0.1118 - val_acc: 0.9824\n",
      "Epoch 33/50\n",
      "120/120 [==============================] - 7s 62ms/step - loss: 0.0110 - acc: 0.9969 - val_loss: 0.1425 - val_acc: 0.9761\n",
      "Epoch 34/50\n",
      "120/120 [==============================] - 8s 65ms/step - loss: 0.0083 - acc: 0.9995 - val_loss: 0.3282 - val_acc: 0.9673\n",
      "Epoch 35/50\n",
      "120/120 [==============================] - 8s 63ms/step - loss: 0.0146 - acc: 0.9969 - val_loss: 0.1459 - val_acc: 0.9761\n",
      "Epoch 36/50\n",
      "120/120 [==============================] - 7s 61ms/step - loss: 0.0241 - acc: 0.9964 - val_loss: 0.1336 - val_acc: 0.9761\n",
      "Epoch 37/50\n",
      "120/120 [==============================] - 7s 62ms/step - loss: 0.0225 - acc: 0.9964 - val_loss: 0.0281 - val_acc: 0.9874\n",
      "Epoch 38/50\n",
      "120/120 [==============================] - 7s 61ms/step - loss: 0.0013 - acc: 0.9995 - val_loss: 0.1865 - val_acc: 0.9773\n",
      "Epoch 39/50\n",
      "120/120 [==============================] - 8s 64ms/step - loss: 0.0051 - acc: 0.9984 - val_loss: 0.2426 - val_acc: 0.9698\n",
      "Epoch 40/50\n",
      "120/120 [==============================] - 7s 62ms/step - loss: 0.0061 - acc: 0.9990 - val_loss: 0.0046 - val_acc: 0.9962\n",
      "Epoch 41/50\n",
      "120/120 [==============================] - 7s 62ms/step - loss: 0.0127 - acc: 0.9958 - val_loss: 0.0899 - val_acc: 0.9836\n",
      "Epoch 42/50\n",
      "120/120 [==============================] - 7s 62ms/step - loss: 0.0055 - acc: 0.9984 - val_loss: 0.1191 - val_acc: 0.9798\n",
      "Epoch 43/50\n",
      "120/120 [==============================] - 7s 62ms/step - loss: 0.0067 - acc: 0.9969 - val_loss: 0.0713 - val_acc: 0.9824\n",
      "Epoch 44/50\n",
      "120/120 [==============================] - 7s 62ms/step - loss: 0.0051 - acc: 0.9984 - val_loss: 0.2000 - val_acc: 0.9736\n",
      "Epoch 45/50\n",
      "120/120 [==============================] - 8s 64ms/step - loss: 0.0158 - acc: 0.9958 - val_loss: 0.1088 - val_acc: 0.9773\n",
      "Epoch 46/50\n",
      "120/120 [==============================] - 8s 63ms/step - loss: 8.7152e-05 - acc: 1.0000 - val_loss: 0.0729 - val_acc: 0.9849\n",
      "Epoch 47/50\n",
      "120/120 [==============================] - 7s 62ms/step - loss: 4.1132e-04 - acc: 0.9995 - val_loss: 0.0622 - val_acc: 0.9899\n",
      "Epoch 48/50\n",
      "120/120 [==============================] - 7s 62ms/step - loss: 0.0178 - acc: 0.9984 - val_loss: 0.2694 - val_acc: 0.9723\n",
      "Epoch 49/50\n",
      "120/120 [==============================] - 7s 61ms/step - loss: 2.2111e-06 - acc: 1.0000 - val_loss: 0.0553 - val_acc: 0.9887\n",
      "Epoch 50/50\n",
      "120/120 [==============================] - 8s 67ms/step - loss: 0.0390 - acc: 0.9969 - val_loss: 0.3279 - val_acc: 0.9710\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14e8eccf8>"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=1935 // batch_size,\n",
    "        epochs=50,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=810 // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model structure\n",
    "from pathlib import Path\n",
    "model_structure = model.to_json()\n",
    "\n",
    "f = Path('model3_aug_structure.json')\n",
    "f.write_text(model_structure)\n",
    "\n",
    "# save model weights\n",
    "model.save_weights('model3_aug_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model4_aug (from 32 x 32 images)\n",
    "* use model8's structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same', input_shape=(32, 32, 3), activation=\"relu\"))\n",
    "model.add(Conv2D(32, (3, 3), activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same', activation=\"relu\"))\n",
    "model.add(Conv2D(64, (3, 3), activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(2, activation=\"softmax\"))\n",
    "\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "landscape = glob.glob('val_256/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "#with open(\"index_2750.txt\", \"wb\") as fp:   #Pickling\n",
    "#    pickle.dump(index_2750, fp)\n",
    "\n",
    "with open(\"index_2750.txt\", \"rb\") as fp:   # Unpickling\n",
    "    index_2750 = pickle.load(fp)\n",
    "\n",
    "# use index to select files\n",
    "landscape_2750 = []\n",
    "for i in index_2750:\n",
    "    temp_img = cv2.imread(landscape[i])\n",
    "    temp_img_resize = cv2.resize(temp_img, (32, 32))\n",
    "    landscape_2750.append(temp_img_resize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "celeb_align_re32 = []\n",
    "for i in range(0, len(celeb_align)):\n",
    "    temp_img = cv2.imread(celeb_align[i])\n",
    "    temp_img_resize = cv2.resize(temp_img, (32,32))\n",
    "    celeb_align_re32.append(temp_img_resize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "celeb_crop_re32 = []\n",
    "for i in range(0, len(celeb_crop)):\n",
    "    temp_img = cv2.imread(celeb_crop[i])\n",
    "    temp_img_resize = cv2.resize(temp_img, (32,32))\n",
    "    celeb_crop_re32.append(temp_img_resize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_imgs = np.concatenate((landscape_2750, celeb_align_re32, celeb_crop_re32), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5500"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5500"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_full_no = list('0') * 2750\n",
    "label_full_no = [int(i) for i in label_full_no]\n",
    "label_full_no = np.asarray(label_full_no)\n",
    "\n",
    "label_full_yes = list('1') * 2750\n",
    "label_full_yes = [int(i) for i in label_full_yes]\n",
    "label_full_yes = np.asarray(label_full_yes)\n",
    "\n",
    "label_full = np.concatenate((label_full_no, label_full_yes), axis=0)\n",
    "len(label_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_imgs, label_full, test_size = 0.33, stratify=label_full, random_state=1992)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data set to 0-to-1 range\n",
    "X_train = (X_train.astype('float32'))\n",
    "X_test = (X_test.astype('float32'))\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# categorize target variable\n",
    "y_train = keras.utils.to_categorical(y_train, 2)\n",
    "y_test = keras.utils.to_categorical(y_test, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator()\n",
    "\n",
    "# generate augmented train data\n",
    "train_generator = train_datagen.flow(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        batch_size=batch_size)  \n",
    "\n",
    "# this is a similar generator, for validation data\n",
    "validation_generator = test_datagen.flow(\n",
    "        X_test,\n",
    "        y_test,\n",
    "        batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "230/230 [==============================] - 27s 117ms/step - loss: 0.3943 - acc: 0.8095 - val_loss: 0.1502 - val_acc: 0.9452\n",
      "Epoch 2/50\n",
      "230/230 [==============================] - 25s 110ms/step - loss: 0.2171 - acc: 0.9147 - val_loss: 0.1305 - val_acc: 0.9533\n",
      "Epoch 3/50\n",
      "230/230 [==============================] - 25s 110ms/step - loss: 0.1668 - acc: 0.9383 - val_loss: 0.2036 - val_acc: 0.9255\n",
      "Epoch 4/50\n",
      "230/230 [==============================] - 25s 111ms/step - loss: 0.1429 - acc: 0.9418 - val_loss: 0.1212 - val_acc: 0.9522\n",
      "Epoch 5/50\n",
      "230/230 [==============================] - 26s 112ms/step - loss: 0.1423 - acc: 0.9480 - val_loss: 0.1303 - val_acc: 0.9516\n",
      "Epoch 6/50\n",
      "230/230 [==============================] - 26s 112ms/step - loss: 0.1259 - acc: 0.9494 - val_loss: 0.1482 - val_acc: 0.9466\n",
      "Epoch 7/50\n",
      "230/230 [==============================] - 26s 112ms/step - loss: 0.1018 - acc: 0.9598 - val_loss: 0.3177 - val_acc: 0.9049\n",
      "Epoch 8/50\n",
      "230/230 [==============================] - 26s 112ms/step - loss: 0.1180 - acc: 0.9578 - val_loss: 0.1565 - val_acc: 0.9477\n",
      "Epoch 9/50\n",
      "230/230 [==============================] - 26s 112ms/step - loss: 0.1086 - acc: 0.9601 - val_loss: 0.0793 - val_acc: 0.9678\n",
      "Epoch 10/50\n",
      "230/230 [==============================] - 26s 112ms/step - loss: 0.1001 - acc: 0.9625 - val_loss: 0.1122 - val_acc: 0.9583\n",
      "Epoch 11/50\n",
      "230/230 [==============================] - 26s 114ms/step - loss: 0.0904 - acc: 0.9684 - val_loss: 0.0912 - val_acc: 0.9678\n",
      "Epoch 12/50\n",
      "230/230 [==============================] - 26s 112ms/step - loss: 0.0933 - acc: 0.9649 - val_loss: 0.1161 - val_acc: 0.9605\n",
      "Epoch 13/50\n",
      "230/230 [==============================] - 28s 122ms/step - loss: 0.0955 - acc: 0.9666 - val_loss: 0.0694 - val_acc: 0.9739\n",
      "Epoch 14/50\n",
      "230/230 [==============================] - 26s 112ms/step - loss: 0.0865 - acc: 0.9679 - val_loss: 0.1104 - val_acc: 0.9583\n",
      "Epoch 15/50\n",
      "230/230 [==============================] - 26s 113ms/step - loss: 0.0822 - acc: 0.9704 - val_loss: 0.0842 - val_acc: 0.9728\n",
      "Epoch 16/50\n",
      "230/230 [==============================] - 27s 116ms/step - loss: 0.0807 - acc: 0.9745 - val_loss: 0.0915 - val_acc: 0.9717\n",
      "Epoch 17/50\n",
      "230/230 [==============================] - 27s 119ms/step - loss: 0.0730 - acc: 0.9728 - val_loss: 0.0644 - val_acc: 0.9794\n",
      "Epoch 18/50\n",
      "230/230 [==============================] - 27s 118ms/step - loss: 0.0708 - acc: 0.9777 - val_loss: 0.0858 - val_acc: 0.9717\n",
      "Epoch 19/50\n",
      "230/230 [==============================] - 26s 113ms/step - loss: 0.0684 - acc: 0.9750 - val_loss: 0.0966 - val_acc: 0.9655\n",
      "Epoch 20/50\n",
      "230/230 [==============================] - 27s 119ms/step - loss: 0.0748 - acc: 0.9707 - val_loss: 0.0657 - val_acc: 0.9783\n",
      "Epoch 21/50\n",
      "230/230 [==============================] - 27s 117ms/step - loss: 0.0761 - acc: 0.9745 - val_loss: 0.1975 - val_acc: 0.9261\n",
      "Epoch 22/50\n",
      "230/230 [==============================] - 27s 117ms/step - loss: 0.0563 - acc: 0.9812 - val_loss: 0.1550 - val_acc: 0.9555\n",
      "Epoch 23/50\n",
      "230/230 [==============================] - 28s 121ms/step - loss: 0.0717 - acc: 0.9749 - val_loss: 0.0612 - val_acc: 0.9794\n",
      "Epoch 24/50\n",
      "230/230 [==============================] - 27s 119ms/step - loss: 0.0465 - acc: 0.9826 - val_loss: 0.1134 - val_acc: 0.9628\n",
      "Epoch 25/50\n",
      "230/230 [==============================] - 27s 119ms/step - loss: 0.0689 - acc: 0.9750 - val_loss: 0.0694 - val_acc: 0.9778\n",
      "Epoch 26/50\n",
      "230/230 [==============================] - 28s 121ms/step - loss: 0.0628 - acc: 0.9771 - val_loss: 0.0765 - val_acc: 0.9728\n",
      "Epoch 27/50\n",
      "230/230 [==============================] - 27s 117ms/step - loss: 0.0629 - acc: 0.9758 - val_loss: 0.0520 - val_acc: 0.9805\n",
      "Epoch 28/50\n",
      "230/230 [==============================] - 27s 118ms/step - loss: 0.0494 - acc: 0.9829 - val_loss: 0.0781 - val_acc: 0.9767\n",
      "Epoch 29/50\n",
      "230/230 [==============================] - 28s 120ms/step - loss: 0.0512 - acc: 0.9796 - val_loss: 0.0628 - val_acc: 0.9844\n",
      "Epoch 30/50\n",
      "230/230 [==============================] - 27s 119ms/step - loss: 0.0555 - acc: 0.9802 - val_loss: 0.0543 - val_acc: 0.9833\n",
      "Epoch 31/50\n",
      "230/230 [==============================] - 28s 120ms/step - loss: 0.0505 - acc: 0.9818 - val_loss: 0.0952 - val_acc: 0.9744\n",
      "Epoch 32/50\n",
      "230/230 [==============================] - 28s 120ms/step - loss: 0.0515 - acc: 0.9810 - val_loss: 0.1152 - val_acc: 0.9616\n",
      "Epoch 33/50\n",
      "230/230 [==============================] - 27s 118ms/step - loss: 0.0492 - acc: 0.9826 - val_loss: 0.0852 - val_acc: 0.9689\n",
      "Epoch 34/50\n",
      "230/230 [==============================] - 27s 118ms/step - loss: 0.0571 - acc: 0.9785 - val_loss: 0.0754 - val_acc: 0.9789\n",
      "Epoch 35/50\n",
      "230/230 [==============================] - 27s 119ms/step - loss: 0.0418 - acc: 0.9853 - val_loss: 0.0775 - val_acc: 0.9817\n",
      "Epoch 36/50\n",
      "230/230 [==============================] - 28s 123ms/step - loss: 0.0517 - acc: 0.9810 - val_loss: 0.1329 - val_acc: 0.9622\n",
      "Epoch 37/50\n",
      "230/230 [==============================] - 26s 112ms/step - loss: 0.0695 - acc: 0.9769 - val_loss: 0.1151 - val_acc: 0.9611\n",
      "Epoch 38/50\n",
      "230/230 [==============================] - 26s 111ms/step - loss: 0.0419 - acc: 0.9837 - val_loss: 0.0420 - val_acc: 0.9850\n",
      "Epoch 39/50\n",
      "230/230 [==============================] - 26s 113ms/step - loss: 0.0312 - acc: 0.9894 - val_loss: 0.0553 - val_acc: 0.9828\n",
      "Epoch 40/50\n",
      "230/230 [==============================] - 26s 113ms/step - loss: 0.0495 - acc: 0.9812 - val_loss: 0.0769 - val_acc: 0.9744\n",
      "Epoch 41/50\n",
      "230/230 [==============================] - 26s 112ms/step - loss: 0.0588 - acc: 0.9793 - val_loss: 0.0594 - val_acc: 0.9783\n",
      "Epoch 42/50\n",
      "230/230 [==============================] - 26s 113ms/step - loss: 0.0457 - acc: 0.9834 - val_loss: 0.0566 - val_acc: 0.9839\n",
      "Epoch 43/50\n",
      "230/230 [==============================] - 27s 117ms/step - loss: 0.0372 - acc: 0.9867 - val_loss: 0.0687 - val_acc: 0.9822\n",
      "Epoch 44/50\n",
      "230/230 [==============================] - 26s 113ms/step - loss: 0.0440 - acc: 0.9859 - val_loss: 0.0363 - val_acc: 0.9855\n",
      "Epoch 45/50\n",
      "230/230 [==============================] - 26s 111ms/step - loss: 0.0544 - acc: 0.9804 - val_loss: 0.0595 - val_acc: 0.9833\n",
      "Epoch 46/50\n",
      "230/230 [==============================] - 26s 111ms/step - loss: 0.0349 - acc: 0.9878 - val_loss: 0.1453 - val_acc: 0.9644\n",
      "Epoch 47/50\n",
      "230/230 [==============================] - 26s 112ms/step - loss: 0.0416 - acc: 0.9861 - val_loss: 0.0579 - val_acc: 0.9839\n",
      "Epoch 48/50\n",
      "230/230 [==============================] - 27s 119ms/step - loss: 0.0470 - acc: 0.9832 - val_loss: 0.0454 - val_acc: 0.9817\n",
      "Epoch 49/50\n",
      "230/230 [==============================] - 25s 111ms/step - loss: 0.0265 - acc: 0.9908 - val_loss: 0.1155 - val_acc: 0.9705\n",
      "Epoch 50/50\n",
      "230/230 [==============================] - 26s 113ms/step - loss: 0.0375 - acc: 0.9845 - val_loss: 0.0570 - val_acc: 0.9850\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13e53fb70>"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=3685 // batch_size,\n",
    "        epochs=50,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=1815 // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model structure\n",
    "from pathlib import Path\n",
    "model_structure = model.to_json()\n",
    "\n",
    "f = Path('model4_aug_structure.json')\n",
    "f.write_text(model_structure)\n",
    "\n",
    "# save model weights\n",
    "model.save_weights('model4_aug_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model5_aug \n",
    "* refined model4_aug with more conditoins in augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same', input_shape=(32, 32, 3), activation=\"relu\"))\n",
    "model.add(Conv2D(32, (3, 3), activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same', activation=\"relu\"))\n",
    "model.add(Conv2D(64, (3, 3), activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(2, activation=\"softmax\"))\n",
    "\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "        featurewise_center=True,\n",
    "        featurewise_std_normalization=True,\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator()\n",
    "\n",
    "# generate augmented train data\n",
    "train_generator = train_datagen.flow(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        batch_size=batch_size)  \n",
    "\n",
    "# this is a similar generator, for validation data\n",
    "validation_generator = test_datagen.flow(\n",
    "        X_test,\n",
    "        y_test,\n",
    "        batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "230/230 [==============================] - 27s 116ms/step - loss: 0.4292 - acc: 0.8027 - val_loss: 0.5834 - val_acc: 0.6079\n",
      "Epoch 2/50\n",
      "230/230 [==============================] - 26s 111ms/step - loss: 0.3094 - acc: 0.8715 - val_loss: 0.5251 - val_acc: 0.8494\n",
      "Epoch 3/50\n",
      "230/230 [==============================] - 26s 112ms/step - loss: 0.2590 - acc: 0.8942 - val_loss: 0.7501 - val_acc: 0.5509\n",
      "Epoch 4/50\n",
      "230/230 [==============================] - 27s 115ms/step - loss: 0.2349 - acc: 0.9110 - val_loss: 0.3856 - val_acc: 0.8432\n",
      "Epoch 5/50\n",
      "230/230 [==============================] - 26s 114ms/step - loss: 0.2002 - acc: 0.9226 - val_loss: 0.4674 - val_acc: 0.7838\n",
      "Epoch 6/50\n",
      "230/230 [==============================] - 26s 114ms/step - loss: 0.1814 - acc: 0.9268 - val_loss: 0.3875 - val_acc: 0.8371\n",
      "Epoch 7/50\n",
      "230/230 [==============================] - 26s 115ms/step - loss: 0.1857 - acc: 0.9304 - val_loss: 0.3026 - val_acc: 0.8699\n",
      "Epoch 8/50\n",
      "230/230 [==============================] - 26s 115ms/step - loss: 0.1663 - acc: 0.9321 - val_loss: 0.3026 - val_acc: 0.8705\n",
      "Epoch 9/50\n",
      "230/230 [==============================] - 27s 115ms/step - loss: 0.1561 - acc: 0.9385 - val_loss: 0.3751 - val_acc: 0.8560\n",
      "Epoch 10/50\n",
      "230/230 [==============================] - 26s 115ms/step - loss: 0.1549 - acc: 0.9424 - val_loss: 0.2264 - val_acc: 0.9027\n",
      "Epoch 11/50\n",
      "230/230 [==============================] - 27s 115ms/step - loss: 0.1446 - acc: 0.9467 - val_loss: 0.2168 - val_acc: 0.9166\n",
      "Epoch 12/50\n",
      "230/230 [==============================] - 27s 116ms/step - loss: 0.1406 - acc: 0.9475 - val_loss: 0.4059 - val_acc: 0.7993\n",
      "Epoch 13/50\n",
      "230/230 [==============================] - 27s 116ms/step - loss: 0.1431 - acc: 0.9465 - val_loss: 0.2651 - val_acc: 0.8816\n",
      "Epoch 14/50\n",
      "230/230 [==============================] - 27s 116ms/step - loss: 0.1290 - acc: 0.9511 - val_loss: 0.2427 - val_acc: 0.9072\n",
      "Epoch 15/50\n",
      "230/230 [==============================] - 27s 116ms/step - loss: 0.1293 - acc: 0.9505 - val_loss: 0.2125 - val_acc: 0.9155\n",
      "Epoch 16/50\n",
      "230/230 [==============================] - 25s 110ms/step - loss: 0.1310 - acc: 0.9527 - val_loss: 0.2016 - val_acc: 0.9283\n",
      "Epoch 17/50\n",
      "230/230 [==============================] - 52s 225ms/step - loss: 0.1201 - acc: 0.9532 - val_loss: 0.1686 - val_acc: 0.9411\n",
      "Epoch 18/50\n",
      "230/230 [==============================] - 30s 131ms/step - loss: 0.1261 - acc: 0.9548 - val_loss: 0.2658 - val_acc: 0.9005\n",
      "Epoch 19/50\n",
      "230/230 [==============================] - 27s 117ms/step - loss: 0.1146 - acc: 0.9557 - val_loss: 0.3154 - val_acc: 0.8810\n",
      "Epoch 20/50\n",
      "230/230 [==============================] - 27s 116ms/step - loss: 0.1172 - acc: 0.9557 - val_loss: 0.1705 - val_acc: 0.9300\n",
      "Epoch 21/50\n",
      "230/230 [==============================] - 27s 115ms/step - loss: 0.1075 - acc: 0.9590 - val_loss: 0.1409 - val_acc: 0.9472\n",
      "Epoch 22/50\n",
      "230/230 [==============================] - 28s 122ms/step - loss: 0.1009 - acc: 0.9655 - val_loss: 0.3429 - val_acc: 0.8683\n",
      "Epoch 23/50\n",
      "230/230 [==============================] - 26s 112ms/step - loss: 0.1058 - acc: 0.9614 - val_loss: 0.1937 - val_acc: 0.9350\n",
      "Epoch 24/50\n",
      "230/230 [==============================] - 49s 215ms/step - loss: 0.1004 - acc: 0.9633 - val_loss: 0.6319 - val_acc: 0.7693\n",
      "Epoch 25/50\n",
      "230/230 [==============================] - 28s 121ms/step - loss: 0.0976 - acc: 0.9625 - val_loss: 0.1588 - val_acc: 0.9389\n",
      "Epoch 26/50\n",
      "230/230 [==============================] - 26s 114ms/step - loss: 0.1040 - acc: 0.9647 - val_loss: 0.2266 - val_acc: 0.9105\n",
      "Epoch 27/50\n",
      "230/230 [==============================] - 27s 116ms/step - loss: 0.0886 - acc: 0.9620 - val_loss: 0.1874 - val_acc: 0.9261\n",
      "Epoch 28/50\n",
      "230/230 [==============================] - 28s 123ms/step - loss: 0.1054 - acc: 0.9633 - val_loss: 0.1991 - val_acc: 0.9188\n",
      "Epoch 29/50\n",
      "230/230 [==============================] - 27s 119ms/step - loss: 0.1034 - acc: 0.9625 - val_loss: 0.1750 - val_acc: 0.9316\n",
      "Epoch 30/50\n",
      "230/230 [==============================] - 27s 116ms/step - loss: 0.0936 - acc: 0.9644 - val_loss: 0.1853 - val_acc: 0.9277\n",
      "Epoch 31/50\n",
      "230/230 [==============================] - 27s 116ms/step - loss: 0.0879 - acc: 0.9677 - val_loss: 0.1122 - val_acc: 0.9589\n",
      "Epoch 32/50\n",
      "230/230 [==============================] - 27s 117ms/step - loss: 0.1055 - acc: 0.9609 - val_loss: 0.1436 - val_acc: 0.9505\n",
      "Epoch 33/50\n",
      "230/230 [==============================] - 28s 120ms/step - loss: 0.0961 - acc: 0.9660 - val_loss: 0.3657 - val_acc: 0.8316\n",
      "Epoch 34/50\n",
      "230/230 [==============================] - 27s 118ms/step - loss: 0.0952 - acc: 0.9677 - val_loss: 0.2430 - val_acc: 0.9005\n",
      "Epoch 35/50\n",
      "230/230 [==============================] - 27s 118ms/step - loss: 0.0890 - acc: 0.9668 - val_loss: 0.2812 - val_acc: 0.8911\n",
      "Epoch 36/50\n",
      "230/230 [==============================] - 27s 119ms/step - loss: 0.0889 - acc: 0.9638 - val_loss: 0.2694 - val_acc: 0.9049\n",
      "Epoch 37/50\n",
      "230/230 [==============================] - 27s 119ms/step - loss: 0.0922 - acc: 0.9636 - val_loss: 0.1601 - val_acc: 0.9333\n",
      "Epoch 38/50\n",
      "230/230 [==============================] - 27s 118ms/step - loss: 0.0947 - acc: 0.9690 - val_loss: 0.1313 - val_acc: 0.9539\n",
      "Epoch 39/50\n",
      "230/230 [==============================] - 27s 117ms/step - loss: 0.0917 - acc: 0.9657 - val_loss: 0.1522 - val_acc: 0.9389\n",
      "Epoch 40/50\n",
      "230/230 [==============================] - 27s 118ms/step - loss: 0.0845 - acc: 0.9687 - val_loss: 0.2913 - val_acc: 0.8855\n",
      "Epoch 41/50\n",
      "230/230 [==============================] - 27s 117ms/step - loss: 0.0859 - acc: 0.9649 - val_loss: 0.7096 - val_acc: 0.7610\n",
      "Epoch 42/50\n",
      "230/230 [==============================] - 27s 117ms/step - loss: 0.0915 - acc: 0.9660 - val_loss: 0.1875 - val_acc: 0.9183\n",
      "Epoch 43/50\n",
      "230/230 [==============================] - 27s 118ms/step - loss: 0.0804 - acc: 0.9747 - val_loss: 0.3912 - val_acc: 0.8460\n",
      "Epoch 44/50\n",
      "230/230 [==============================] - 27s 118ms/step - loss: 0.0836 - acc: 0.9698 - val_loss: 0.1608 - val_acc: 0.9405\n",
      "Epoch 45/50\n",
      "230/230 [==============================] - 27s 119ms/step - loss: 0.0826 - acc: 0.9679 - val_loss: 0.3371 - val_acc: 0.8677\n",
      "Epoch 46/50\n",
      "230/230 [==============================] - 27s 117ms/step - loss: 0.0879 - acc: 0.9687 - val_loss: 0.1895 - val_acc: 0.9294\n",
      "Epoch 47/50\n",
      "230/230 [==============================] - 27s 120ms/step - loss: 0.0934 - acc: 0.9636 - val_loss: 0.1316 - val_acc: 0.9555\n",
      "Epoch 48/50\n",
      "230/230 [==============================] - 26s 114ms/step - loss: 0.0872 - acc: 0.9663 - val_loss: 0.7858 - val_acc: 0.7399\n",
      "Epoch 49/50\n",
      "230/230 [==============================] - 1089s 5s/step - loss: 0.0732 - acc: 0.9745 - val_loss: 0.2132 - val_acc: 0.9216\n",
      "Epoch 50/50\n",
      "230/230 [==============================] - 30s 130ms/step - loss: 0.0843 - acc: 0.9652 - val_loss: 0.3220 - val_acc: 0.8588\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14fed5198>"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=3685 // batch_size,\n",
    "        epochs=50,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=1815 // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model structure\n",
    "from pathlib import Path\n",
    "model_structure = model.to_json()\n",
    "\n",
    "f = Path('model5_aug_structure.json')\n",
    "f.write_text(model_structure)\n",
    "\n",
    "# save model weights\n",
    "model.save_weights('model5_aug_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
